{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\u001b[2m2017-12-06 00:49.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1menv-capture                   \u001b[0m [\u001b[34m\u001b[1mdrugdiscovery\u001b[0m] \u001b[36menv\u001b[0m=\u001b[35m'prod'\u001b[0m \u001b[36mversion\u001b[0m=\u001b[35m'0.5+960.g44ec64a9.dirty'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os, random, sys, keras\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import drugdiscovery as dd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(np.min(X_train), np.max(X_train))\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shp = X_train.shape[1:]\n",
    "dropout_rate = 0.2\n",
    "opt = Adam(lr=1e-4)\n",
    "dopt = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,394,241.0\n",
      "Trainable params: 2,368,705.0\n",
      "Non-trainable params: 25,536.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Generative model ...\n",
    "depth = 64*4\n",
    "dim = 7\n",
    "generator = Sequential()\n",
    "\n",
    "generator.add(Dense(dim*dim*depth, kernel_initializer='glorot_normal', input_dim=100))\n",
    "generator.add(BatchNormalization(momentum=.9))\n",
    "generator.add(Activation('relu'))\n",
    "generator.add(Reshape( [dim,dim,depth] ))\n",
    "generator.add(Dropout(dropout_rate))\n",
    "\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2DTranspose(depth//2, 5, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=.9))\n",
    "generator.add(Activation('relu'))\n",
    "\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2DTranspose(depth//4, 5, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=.9))\n",
    "generator.add(Activation('relu'))\n",
    "\n",
    "generator.add(Conv2DTranspose(depth//8, 5, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=.9))\n",
    "generator.add(Activation('relu'))\n",
    "\n",
    "generator.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "generator.add(Activation('sigmoid'))\n",
    "\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,305,409.0\n",
      "Trainable params: 4,305,409.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Discriminative model ...\n",
    "depth = 64\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(depth*1, 5, padding='same', activation='relu', strides=2,\n",
    "                        input_shape=input_shape))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(dropout_rate))\n",
    "\n",
    "discriminator.add(Conv2D(depth*2, 5, padding='same', activation='relu', strides=2))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(dropout_rate))\n",
    "\n",
    "discriminator.add(Conv2D(depth*4, 5, padding='same', activation='relu', strides=2))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(dropout_rate))\n",
    "\n",
    "discriminator.add(Conv2D(depth*8, 5, padding='same', activation='relu', strides=2))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(dropout_rate))\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1))\n",
    "discriminator.add(Activation('sigmoid'))\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=dopt, metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         2394241   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 4305409   \n",
      "=================================================================\n",
      "Total params: 6,699,650.0\n",
      "Trainable params: 2,368,705.0\n",
      "Non-trainable params: 4,330,945.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Freeze weights in the discriminator for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "make_trainable(discriminator, False)\n",
    "\n",
    "# Build stacked GAN model\n",
    "GAN = Sequential()\n",
    "GAN.add(generator)\n",
    "GAN.add(discriminator)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "#        display.clear_output(wait=True)\n",
    "#        display.display(plt.gcf())\n",
    "    d_loss, d_acc = zip(*losses['d'])\n",
    "    g_loss, g_acc = zip(*losses['g'])\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(12,3))\n",
    "\n",
    "    ax1.set_title('Losses')\n",
    "    ax1.plot(d_loss, label='discriminator')\n",
    "    ax1.plot(g_loss, label='generator')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.plot(d_acc, label='discriminator')\n",
    "    ax2.plot(g_acc, label='generator')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_gen(n_ex=6, dim=(1,6), figsize=(6,1), fixed_noise=None):\n",
    "    noise = np.random.uniform(0,1,size=[n_ex,100])\n",
    "    if fixed_noise is not None:\n",
    "        noise[:fixed_noise.shape[0],:] = fixed_noise[:,:]\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = generated_images[i,:,:,0]\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_real(n_ex=16,dim=(4,4), figsize=(6,6) ):\n",
    "    \n",
    "    idx = np.random.randint(0,X_train.shape[0],n_ex)\n",
    "    generated_images = X_train[idx,:,:,0]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = generated_images[i,:,:]\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2048/2048 [==============================] - ETA: 28s - loss: 0.6935 - acc: 0.51 - ETA: 22s - loss: 0.5534 - acc: 0.60 - ETA: 20s - loss: 3.0913 - acc: 0.55 - ETA: 17s - loss: 2.4135 - acc: 0.60 - ETA: 16s - loss: 2.1395 - acc: 0.58 - ETA: 14s - loss: 1.8710 - acc: 0.58 - ETA: 13s - loss: 1.6439 - acc: 0.64 - ETA: 11s - loss: 1.4894 - acc: 0.65 - ETA: 10s - loss: 1.3453 - acc: 0.69 - ETA: 8s - loss: 1.2188 - acc: 0.7227 - ETA: 7s - loss: 1.1206 - acc: 0.742 - ETA: 5s - loss: 1.0344 - acc: 0.763 - ETA: 4s - loss: 0.9581 - acc: 0.780 - ETA: 2s - loss: 0.8934 - acc: 0.794 - ETA: 1s - loss: 0.8340 - acc: 0.808 - 22s - loss: 0.7822 - acc: 0.8203    \n",
      "Accuracy: 100.00 pct (2048 of 2048) right\n"
     ]
    }
   ],
   "source": [
    "ntrain = 1024\n",
    "trainidx = random.sample(range(0,X_train.shape[0]), ntrain)\n",
    "XT = X_train[trainidx,:,:,:]\n",
    "\n",
    "# Pre-train the discriminator network ...\n",
    "noise_gen = np.random.uniform(0,1,size=[XT.shape[0],100])\n",
    "generated_images = generator.predict(noise_gen)\n",
    "X = np.concatenate((XT, generated_images))\n",
    "n = XT.shape[0]\n",
    "y = np.zeros([2*n,1])\n",
    "y[n:] = 1\n",
    "\n",
    "make_trainable(discriminator,True)\n",
    "discriminator.fit(X,y, epochs=1, batch_size=128)\n",
    "y_hat = discriminator.predict(X)\n",
    "\n",
    "# Measure accuracy of pre-trained discriminator network\n",
    "y_hat_idx = np.argmax(y_hat,axis=1)\n",
    "y_idx = np.argmax(y,axis=1)\n",
    "diff = y_idx-y_hat_idx\n",
    "n_tot = y.shape[0]\n",
    "n_rig = (diff==0).sum()\n",
    "acc = n_rig*100.0/n_tot\n",
    "print(\"Accuracy: %0.02f pct (%d of %d) right\" % (acc, n_rig, n_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup tensorboard\n",
    "def write_log(callback, names, logs, batch_no):\n",
    "    for name, value in zip(names, logs):\n",
    "        summary = tf.Summary()\n",
    "        summary_value = summary.value.add()\n",
    "        summary_value.simple_value = value\n",
    "        summary_value.tag = name\n",
    "        callback.writer.add_summary(summary, batch_no)\n",
    "        callback.writer.flush()\n",
    "    \n",
    "log_path_g = './logs/generator'\n",
    "callback_g = TensorBoard(log_path_g)\n",
    "callback_g.set_model(GAN)\n",
    "\n",
    "log_path_d = './logs/discriminator'\n",
    "callback_d = TensorBoard(log_path_d)\n",
    "callback_d.set_model(discriminator)\n",
    "\n",
    "callback_names = ['loss', 'acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some fixed noise inputs for watching progression\n",
    "fixed_noise = np.random.uniform(0,1,size=[3,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up loss storage vector\n",
    "losses = {\"d\":[], \"g\":[]}\n",
    "\n",
    "# Set up our main training loop\n",
    "def train_for_n(nb_epoch=10000, plt_frq=200, BATCH_SIZE=32):\n",
    "    opt.lr.assign(1e-4)\n",
    "    dopt.lr.assign(1e-3)\n",
    "    \n",
    "    for e in tqdm(range(nb_epoch)):\n",
    "        # lower the learning rates for later batches\n",
    "        if e == 6000:\n",
    "            opt.lr.assign(1e-5)\n",
    "            dopt.lr.assign(1e-4)\n",
    "        if e == 8000:\n",
    "            opt.lr.assign(1e-6)\n",
    "            dopt.lr.assign(1e-5)\n",
    "        \n",
    "        # Make generative images\n",
    "        image_batch = X_train[np.random.randint(0,X_train.shape[0],size=BATCH_SIZE),:,:,:]    \n",
    "        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
    "        generated_images = generator.predict(noise_gen)\n",
    "        \n",
    "        # Train discriminator on generated images\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        y = np.zeros([2*BATCH_SIZE,1])\n",
    "        y[BATCH_SIZE:] = 1\n",
    "#         if e%10==0:\n",
    "#             y = np.ones([2*BATCH_SIZE,1])\n",
    "#             y[BATCH_SIZE:] = 0\n",
    "        \n",
    "        make_trainable(discriminator,True)\n",
    "        d_log  = discriminator.train_on_batch(X, y)\n",
    "        losses[\"d\"].append(d_log)\n",
    "        write_log(callback_d, callback_names, d_log, e)\n",
    "    \n",
    "        # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "        noise_tr = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
    "        y2 = np.zeros([BATCH_SIZE,1])\n",
    "        \n",
    "        if e%10 != 0:\n",
    "            make_trainable(discriminator,False)\n",
    "        g_log = GAN.train_on_batch(noise_tr, y2)\n",
    "        losses[\"g\"].append(g_log)\n",
    "        write_log(callback_g, callback_names, g_log, e)\n",
    "        \n",
    "        # plot samples\n",
    "        if e%plt_frq==0 or (e < 200 and e%50==0):\n",
    "            plot_gen(fixed_noise=fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABSCAYAAABE4S/MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1614f57b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/10000 [00:07<21:45:56,  7.84s/it]\u001b[A\n",
      "  0%|          | 6/10000 [00:25<11:48:47,  4.26s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e6bce30102b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_for_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt_frq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-090f341e5ae3>\u001b[0m in \u001b[0;36mtrain_for_n\u001b[0;34m(nb_epoch, plt_frq, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mmake_trainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mg_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"g\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mwrite_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drugdiscovery/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    931\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    932\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m~/miniconda3/envs/drugdiscovery/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drugdiscovery/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drugdiscovery/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drugdiscovery/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drugdiscovery/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drugdiscovery/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drugdiscovery/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train!!\n",
    "train_for_n(nb_epoch=10000, plt_frq=200, BATCH_SIZE=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the final loss curves\n",
    "plot_loss(losses)\n",
    "\n",
    "# Plot some generated images from our GAN\n",
    "plot_gen(25,(5,5),(6,6))\n",
    "\n",
    "# Plot real MNIST images for comparison\n",
    "plot_real(25,(5,5),(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drugdiscovery]",
   "language": "python",
   "name": "conda-env-drugdiscovery-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
