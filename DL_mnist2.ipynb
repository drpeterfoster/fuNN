{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\u001b[2m2017-12-05 22:53.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1menv-capture                   \u001b[0m [\u001b[34m\u001b[1mdrugdiscovery\u001b[0m] \u001b[36menv\u001b[0m=\u001b[35m'prod'\u001b[0m \u001b[36mversion\u001b[0m=\u001b[35m'0.5+960.g44ec64a9.dirty'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os, random, sys, keras\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import drugdiscovery as dd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(np.min(X_train), np.max(X_train))\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shp = X_train.shape[1:]\n",
    "dropout_rate = 0.2\n",
    "opt = Adam(lr=1e-4)\n",
    "dopt = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,394,241.0\n",
      "Trainable params: 2,368,705.0\n",
      "Non-trainable params: 25,536.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Generative model ...\n",
    "depth = 64*4\n",
    "dim = 7\n",
    "generator = Sequential()\n",
    "\n",
    "generator.add(Dense(dim*dim*depth, kernel_initializer='glorot_normal', input_dim=100))\n",
    "generator.add(BatchNormalization(momentum=.9))\n",
    "generator.add(Activation('relu'))\n",
    "generator.add(Reshape( [dim,dim,depth] ))\n",
    "generator.add(Dropout(dropout_rate))\n",
    "\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2DTranspose(depth//2, 5, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=.9))\n",
    "generator.add(Activation('relu'))\n",
    "\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2DTranspose(depth//4, 5, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=.9))\n",
    "generator.add(Activation('relu'))\n",
    "\n",
    "generator.add(Conv2DTranspose(depth//8, 5, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=.9))\n",
    "generator.add(Activation('relu'))\n",
    "\n",
    "generator.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "generator.add(Activation('sigmoid'))\n",
    "\n",
    "generator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 2049      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,305,409.0\n",
      "Trainable params: 4,305,409.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Discriminative model ...\n",
    "depth = 64\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(depth*1, 5, padding='same', activation='relu', strides=2,\n",
    "                        input_shape=input_shape))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(dropout_rate))\n",
    "\n",
    "discriminator.add(Conv2D(depth*2, 5, padding='same', activation='relu', strides=2))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(dropout_rate))\n",
    "\n",
    "discriminator.add(Conv2D(depth*4, 5, padding='same', activation='relu', strides=2))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(dropout_rate))\n",
    "\n",
    "discriminator.add(Conv2D(depth*8, 5, padding='same', activation='relu', strides=2))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(dropout_rate))\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1))\n",
    "discriminator.add(Activation('sigmoid'))\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=dopt, metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_5 (Sequential)    (None, 28, 28, 1)         2394241   \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 1)                 4305409   \n",
      "=================================================================\n",
      "Total params: 6,699,650.0\n",
      "Trainable params: 2,368,705.0\n",
      "Non-trainable params: 4,330,945.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Freeze weights in the discriminator for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "make_trainable(discriminator, False)\n",
    "\n",
    "# Build stacked GAN model\n",
    "GAN = Sequential()\n",
    "GAN.add(generator)\n",
    "GAN.add(discriminator)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "#        display.clear_output(wait=True)\n",
    "#        display.display(plt.gcf())\n",
    "    d_loss, d_acc = zip(*losses['d'])\n",
    "    g_loss, g_acc = zip(*losses['g'])\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(12,3))\n",
    "\n",
    "    ax1.set_title('Losses')\n",
    "    ax1.plot(d_loss, label='discriminator')\n",
    "    ax1.plot(g_loss, label='generator')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.plot(d_acc, label='discriminator')\n",
    "    ax2.plot(g_acc, label='generator')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_gen(n_ex=6, dim=(1,6), figsize=(6,1), fixed_noise=None):\n",
    "    noise = np.random.uniform(0,1,size=[n_ex,100])\n",
    "    if fixed_noise is not None:\n",
    "        noise[:fixed_noise.shape[0],:] = fixed_noise[:,:]\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = generated_images[i,:,:,0]\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_real(n_ex=16,dim=(4,4), figsize=(6,6) ):\n",
    "    \n",
    "    idx = np.random.randint(0,X_train.shape[0],n_ex)\n",
    "    generated_images = X_train[idx,:,:,0]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = generated_images[i,:,:]\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2048/2048 [==============================] - ETA: 29s - loss: 0.6919 - acc: 0.49 - ETA: 23s - loss: 0.5699 - acc: 0.74 - ETA: 20s - loss: 1.1853 - acc: 0.66 - ETA: 18s - loss: 1.0129 - acc: 0.66 - ETA: 16s - loss: 0.9450 - acc: 0.67 - ETA: 14s - loss: 0.8308 - acc: 0.71 - ETA: 13s - loss: 0.7122 - acc: 0.75 - ETA: 11s - loss: 0.6414 - acc: 0.78 - ETA: 10s - loss: 0.5715 - acc: 0.80 - ETA: 8s - loss: 0.5158 - acc: 0.8227 - ETA: 7s - loss: 0.4725 - acc: 0.838 - ETA: 5s - loss: 0.4422 - acc: 0.849 - ETA: 4s - loss: 0.4190 - acc: 0.860 - ETA: 2s - loss: 0.3891 - acc: 0.870 - ETA: 1s - loss: 0.3649 - acc: 0.877 - 22s - loss: 0.3421 - acc: 0.8853    \n",
      "Accuracy: 100.00 pct (2048 of 2048) right\n"
     ]
    }
   ],
   "source": [
    "ntrain = 1024\n",
    "trainidx = random.sample(range(0,X_train.shape[0]), ntrain)\n",
    "XT = X_train[trainidx,:,:,:]\n",
    "\n",
    "# Pre-train the discriminator network ...\n",
    "noise_gen = np.random.uniform(0,1,size=[XT.shape[0],100])\n",
    "generated_images = generator.predict(noise_gen)\n",
    "X = np.concatenate((XT, generated_images))\n",
    "n = XT.shape[0]\n",
    "y = np.zeros([2*n,1])\n",
    "y[n:] = 1\n",
    "\n",
    "make_trainable(discriminator,True)\n",
    "discriminator.fit(X,y, epochs=1, batch_size=128)\n",
    "y_hat = discriminator.predict(X)\n",
    "\n",
    "# Measure accuracy of pre-trained discriminator network\n",
    "y_hat_idx = np.argmax(y_hat,axis=1)\n",
    "y_idx = np.argmax(y,axis=1)\n",
    "diff = y_idx-y_hat_idx\n",
    "n_tot = y.shape[0]\n",
    "n_rig = (diff==0).sum()\n",
    "acc = n_rig*100.0/n_tot\n",
    "print(\"Accuracy: %0.02f pct (%d of %d) right\" % (acc, n_rig, n_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup tensorboard\n",
    "def write_log(callback, names, logs, batch_no):\n",
    "    for name, value in zip(names, logs):\n",
    "        summary = tf.Summary()\n",
    "        summary_value = summary.value.add()\n",
    "        summary_value.simple_value = value\n",
    "        summary_value.tag = name\n",
    "        callback.writer.add_summary(summary, batch_no)\n",
    "        callback.writer.flush()\n",
    "    \n",
    "log_path_g = './logs/generator'\n",
    "callback_g = TensorBoard(log_path_g)\n",
    "callback_g.set_model(GAN)\n",
    "\n",
    "log_path_d = './logs/discriminator'\n",
    "callback_d = TensorBoard(log_path_d)\n",
    "callback_d.set_model(discriminator)\n",
    "\n",
    "callback_names = ['loss', 'acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some fixed noise inputs for watching progression\n",
    "fixed_noise = np.random.uniform(0,1,size=[3,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up loss storage vector\n",
    "losses = {\"d\":[], \"g\":[]}\n",
    "\n",
    "# Set up our main training loop\n",
    "def train_for_n(nb_epoch=10000, plt_frq=200, BATCH_SIZE=32):\n",
    "    opt.lr.assign(5e-4)\n",
    "    dopt.lr.assign(1e-3)\n",
    "    \n",
    "    for e in tqdm(range(nb_epoch)):\n",
    "        # lower the learning rates for later batches\n",
    "        if e == 6000:\n",
    "            opt.lr.assign(5e-5)\n",
    "            dopt.lr.assign(1e-4)\n",
    "        if e == 8000:\n",
    "            opt.lr.assign(5e-6)\n",
    "            dopt.lr.assign(1e-5)\n",
    "        \n",
    "        # Make generative images\n",
    "        image_batch = X_train[np.random.randint(0,X_train.shape[0],size=BATCH_SIZE),:,:,:]    \n",
    "        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
    "        generated_images = generator.predict(noise_gen)\n",
    "        \n",
    "        # Train discriminator on generated images\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        y = np.zeros([2*BATCH_SIZE,1])\n",
    "        y[BATCH_SIZE:] = 1\n",
    "        if e%10==0:\n",
    "            y = np.ones([2*BATCH_SIZE,1])\n",
    "            y[BATCH_SIZE:] = 0\n",
    "        \n",
    "        make_trainable(discriminator,True)\n",
    "        d_log  = discriminator.train_on_batch(X, y)\n",
    "        losses[\"d\"].append(d_log)\n",
    "        write_log(callback_d, callback_names, d_log, e)\n",
    "    \n",
    "        # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "        noise_tr = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
    "        y2 = np.zeros([BATCH_SIZE,1])\n",
    "        \n",
    "        make_trainable(discriminator,False)\n",
    "        g_log = GAN.train_on_batch(noise_tr, y2)\n",
    "        losses[\"g\"].append(g_log)\n",
    "        write_log(callback_g, callback_names, g_log, e)\n",
    "        \n",
    "        # plot samples\n",
    "        if e%plt_frq==0 or (e < 200 and e%50==0):\n",
    "            plot_gen(fixed_noise=fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABSCAYAAABE4S/MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR5ngvwGQzZAkwxYmCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15589c320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/10000 [00:22<13:00:01,  4.68s/it]"
     ]
    }
   ],
   "source": [
    "# Train!!\n",
    "train_for_n(nb_epoch=10000, plt_frq=200, BATCH_SIZE=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the final loss curves\n",
    "plot_loss(losses)\n",
    "\n",
    "# Plot some generated images from our GAN\n",
    "plot_gen(25,(5,5),(6,6))\n",
    "\n",
    "# Plot real MNIST images for comparison\n",
    "plot_real(25,(5,5),(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drugdiscovery]",
   "language": "python",
   "name": "conda-env-drugdiscovery-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
